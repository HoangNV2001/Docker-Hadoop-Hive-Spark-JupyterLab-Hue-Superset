version: "3.6"

services:

#Hà đụp
  namenode:
    image: johannestang/hadoop-namenode:2.0.0-hadoop2.8.5-java8
    container_name: namenode
    restart: always
    volumes:
      - /tmp/hdfs/namenode:/hadoop/dfs/name
      - shared-workspace:/opt/workspace
    environment:
      - CLUSTER_NAME=bigdata-tp
    env_file:
      - ./hadoop-hive.env
    ports:
      - "50070:50070"
    networks:
      my_network:
        ipv4_address: 172.27.1.5

  datanode:
    image: johannestang/hadoop-datanode:2.0.0-hadoop2.8.5-java8
    container_name: datanode
    restart: always
    volumes:
      - /tmp/hdfs/datanode:/hadoop/dfs/data
      - ./bank:/bank
      - shared-workspace:/opt/workspace
    env_file:
      - ./hadoop-hive.env
    environment:
      SERVICE_PRECONDITION: "namenode:50070"
    depends_on:
      - namenode
    ports:
      - "50075:50075"
    networks:
      my_network:
        ipv4_address: 172.27.1.6

# Mắc Hìve
  hive-server:
    image: bde2020/hive:2.3.2-postgresql-metastore
    container_name: hive-server
    env_file:
      - ./hadoop-hive.env
    environment:
      HIVE_CORE_CONF_javax_jdo_option_ConnectionURL: "jdbc:postgresql://hive-metastore/metastore"
      SERVICE_PRECONDITION: "hive-metastore:9083"
    ports:
      - "10000:10000"
      - "10002:10002"
    # depends_on:
    #   - hive-metastore
    networks:
      my_network:
        ipv4_address: 172.27.1.7

  hive-metastore:
    image: bde2020/hive:2.3.2-postgresql-metastore
    container_name: hive-metastore
    env_file:
      - ./hadoop-hive.env
    command: /opt/hive/bin/hive --service metastore
    environment:
      SERVICE_PRECONDITION: "namenode:50070 datanode:50075 hive-metastore-postgresql:5432"
    ports:
      - "9083:9083"
    depends_on:
      - hive-metastore-postgresql
    networks:
      my_network:
        ipv4_address: 172.27.1.8
  
  hive-metastore-postgresql:
    image: bde2020/hive-metastore-postgresql:2.3.0
    container_name: hive-metastore-postgresql
    ports:
      - "5432:5432"
    # depends_on:
    #   - datanode
    networks:
      my_network:
        ipv4_address: 172.27.1.9

# #Presto
#   presto-coordinator:
#     image: shawnzhu/prestodb:0.181
#     ports:
#     - "8090:8080"

#Huề
  huedb:
    image: postgres:12.1-alpine
    container_name: huedb
    volumes:
        - pg_data:/var/lib/postgresl/data/
    ports:
      - "5432"
    env_file:
      - ./hadoop-hive.env
    environment:
        SERVICE_PRECONDITION: "namenode:50070 datanode:50075 hive-metastore-postgresql:5432 hive-metastore:9083"
    networks:
      my_network:
        ipv4_address: 172.27.1.10

  hue:
    image: gethue/hue:4.6.0
    container_name: hue
    environment:
      SERVICE_PRECONDITION: "namenode:50070 datanode:50075 hive-metastore-postgresql:5432 hive-metastore:9083 huedb:5000"
    # dns: 8.8.8.8
    ports:
    - "8989:8888"
    volumes:
      - ./hue-overrides.ini:/usr/share/hue/desktop/conf/z-hue.ini
    # depends_on:
    links:
      - huedb
    networks:
      my_network:
        ipv4_address: 172.27.1.11



# Not-zeppelin
  jupyterlab:
    image: andreper/jupyterlab:3.0.0-spark-3.0.0
    container_name: jupyterlab
    ports:
      - 8888:8888
      - 4040:4040
    volumes:
      - shared-workspace:/opt/workspace
    networks:
      my_network:
        ipv4_address: 172.27.1.12

  spark-master:
    image: andreper/spark-master:3.0.0
    container_name: spark-master
    ports:
      - 8080:8080
      - 7077:7077
    volumes:
      - shared-workspace:/opt/workspace
    networks:
      my_network:
        ipv4_address: 172.27.1.13

  spark-worker-1:
    image: andreper/spark-worker:3.0.0
    container_name: spark-worker-1
    environment:
      - SPARK_WORKER_CORES=1
      - SPARK_WORKER_MEMORY=512m
    ports:
      - 8081:8081
    volumes:
      - shared-workspace:/opt/workspace
    depends_on:
      - spark-master
    networks:
      my_network:
        ipv4_address: 172.27.1.14

  spark-worker-2:
    image: andreper/spark-worker:3.0.0
    container_name: spark-worker-2
    environment:
      - SPARK_WORKER_CORES=1
      - SPARK_WORKER_MEMORY=512m
    ports:
      - 8082:8082
    volumes:
      - shared-workspace:/opt/workspace
    depends_on:
      - spark-master
    networks:
      my_network:
        ipv4_address: 172.27.1.15

#Siêu sấm sét
  superset-redis:
    image: redis:3.2
    container_name: superset_redis
    restart: always
    ports:
      - 6379:6379
    volumes:
      - redis:/data

  superset-mysql:
    image: mysql:5.7
    container_name: superset_mysql
    restart: always
    environment:
      MYSQL_USER: superset
      MYSQL_PASSWORD: superset
      MYSQL_DATABASE: superset
      MYSQL_ROOT_PASSWORD: root
    ports:
      - 3306:3306
    volumes:
      - mysql:/var/lib/mysql

  superset:
    image: abhioncbr/docker-superset:0.29.0rc5
    container_name: superset
    restart: always
    environment:
      MYSQL_USER: superset
      MYSQL_PASS: superset
      MYSQL_DATABASE: superset
      MYSQL_HOST: superset-mysql
      MYSQL_PORT: 3306
      REDIS_HOST: superset-redis
      REDIS_PORT: 6379
      SUPERSET_ENV: local
      GOOGLE_APPLICATION_CREDENTIALS: 
    ports:
      - 8089:8088
      - 5555:5555
    depends_on:
      - superset-mysql
      - superset-redis
    volumes:
      - ../config/:/home/superset/config/

# # Minion
#   minio:
#     image: minio/minio:RELEASE.2019-10-12T01-39-57Z
#     container_name: minio
#     restart: always
#     ports:
#       - "9000:9000"
#     environment:
#       MINIO_ACCESS_KEY: minio_user
#       MINIO_SECRET_KEY: minio_user
#     volumes:
#       - ./minio/data:/data
#       - ./minio/config:/root/.minio
#     command: server /data


volumes:
  # nifi-conf:
  mysql:
    external: false
  redis:
    external: false
  shared-workspace:
    name: "hadoop-distributed-file-system"
    driver: local
  pg_data:
networks:
  my_network:
    ipam:
      driver: default
      config:
        - subnet: 172.27.0.0/16


